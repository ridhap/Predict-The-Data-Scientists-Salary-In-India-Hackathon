{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Final_Train_Dataset.csv')\n",
    "test = pd.read_csv('Final_Test_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experience</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_type</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>6to10</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>10to15</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5-9 yrs</td>\n",
       "      <td>Must be an effective communicator (written &amp; s...</td>\n",
       "      <td>Deputy Manager - Talent Management &amp; Leadershi...</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>HR Analytics, Employee Engagement, Training, S...</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>15to25</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7-10 yrs</td>\n",
       "      <td>7  -  10 years of overall experience in data e...</td>\n",
       "      <td>Associate Manager Data Engineering</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>SQL, Javascript, Automation, Python, Ruby, Ana...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>10to15</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1-3 yrs</td>\n",
       "      <td>Chartered Accountancy degree or MBA in Finance...</td>\n",
       "      <td>TS- GSA- Senior Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accounting, finance, cash flow, financial plan...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3to6</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 experience                                    job_description  \\\n",
       "0           0    5-7 yrs  Exp: Minimum 5 years;Good understanding of IOC...   \n",
       "1           1  10-17 yrs  He should have handled a team of atleast 5-6 d...   \n",
       "2           2    5-9 yrs  Must be an effective communicator (written & s...   \n",
       "3           3   7-10 yrs  7  -  10 years of overall experience in data e...   \n",
       "4           4    1-3 yrs  Chartered Accountancy degree or MBA in Finance...   \n",
       "\n",
       "                                           job_desig   job_type  \\\n",
       "0        Senior Exploit and Vulnerability Researcher        NaN   \n",
       "1                                           Head SCM        NaN   \n",
       "2  Deputy Manager - Talent Management & Leadershi...  Analytics   \n",
       "3                 Associate Manager Data Engineering  Analytics   \n",
       "4                            TS- GSA- Senior Analyst        NaN   \n",
       "\n",
       "                                          key_skills               location  \\\n",
       "0  team skills, communication skills, analytical ...  Delhi NCR(Vikas Puri)   \n",
       "1  ppc, logistics, inventory management, supply c...                Sonepat   \n",
       "2  HR Analytics, Employee Engagement, Training, S...              Delhi NCR   \n",
       "3  SQL, Javascript, Automation, Python, Ruby, Ana...              Bengaluru   \n",
       "4  accounting, finance, cash flow, financial plan...                Gurgaon   \n",
       "\n",
       "   salary  company_name_encoded  \n",
       "0   6to10                  3687  \n",
       "1  10to15                   458  \n",
       "2  15to25                  4195  \n",
       "3  10to15                   313  \n",
       "4    3to6                  1305  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['key_skills'])\n",
    "\n",
    "df_train = train[['key_skills', 'job_desig', 'job_description', 'location', 'job_type', 'experience','salary']]\n",
    "df_test = test[['key_skills', 'job_desig', 'job_description', 'job_type', 'experience', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_skills(skl):\n",
    "    skills = str(skl).lower()\n",
    "    skills = re.sub(r'\\s+', ' ', skills)\n",
    "    skills = re.sub(r',','', skills)\n",
    "    skills = re.sub(r'\\...','', skills)\n",
    "    return skills\n",
    "\n",
    "df_train['skills_cleaned'] = df_train['key_skills'].apply(cleaning_skills)\n",
    "df_test['skills_cleaned'] = df_test['key_skills'].apply(cleaning_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_designation(desig):\n",
    "    job_desig = desig.lower()\n",
    "    job_desig = re.sub(r'[^a-z]', ' ', job_desig)\n",
    "    job_desig = re.sub(r'\\s+', ' ', job_desig)\n",
    "    return job_desig\n",
    "\n",
    "df_train['desig_cleaned'] = df_train['job_desig'].apply(clean_job_designation)\n",
    "df_test['desig_cleaned'] = df_test['job_desig'].apply(clean_job_designation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_description'].fillna('missing', inplace=True)\n",
    "test['job_description'].fillna('missing', inplace=True)\n",
    "\n",
    "def clean_job_description(job):\n",
    "    job_desc = str(job).lower()\n",
    "    job_desc = re.sub(r'[^a-z]', ' ', job_desc)\n",
    "    job_desc = re.sub(r'\\s+', ' ', job_desc)\n",
    "    return job_desc\n",
    "\n",
    "df_train['job_desc_cleaned'] = df_train['job_description'].apply(clean_job_description)\n",
    "df_test['job_desc_cleaned'] = df_test['job_description'].apply(clean_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(loc):\n",
    "    location = loc.lower()\n",
    "    location = re.sub(r'[^a-z]', ' ', location)\n",
    "    location = re.sub(r'\\s+', ' ', location)\n",
    "    return location\n",
    "\n",
    "df_train['loc_cleaned'] = df_train['location'].apply(clean_location)\n",
    "df_test['loc_cleaned'] = df_test['location'].apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_type'].fillna('missingjobtype', inplace=True)\n",
    "train['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "train['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "train['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "train['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "test['job_type'].fillna('missingjobtype', inplace=True)\n",
    "test['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "test['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "test['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "test['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "df_train['job_type_cleaned'] = train['job_type'] \n",
    "df_test['job_type_cleaned'] = test['job_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_exp(exp):\n",
    "    val = re.sub(r'-',' ', exp)\n",
    "    val = val.split(' ')\n",
    "    val = int(val[0])\n",
    "    return val\n",
    "\n",
    "def max_exp(exp):\n",
    "    val = re.sub(r'-',' ', exp)\n",
    "    val = val.split(' ')\n",
    "    val = int(val[1])\n",
    "    return val\n",
    "\n",
    "df_train['min_exp'] = df_train['experience'].apply(min_exp)\n",
    "df_train['max_exp'] = df_train['experience'].apply(max_exp)\n",
    "\n",
    "df_test['min_exp'] = df_test['experience'].apply(min_exp)\n",
    "df_test['max_exp'] = df_test['experience'].apply(max_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_skills</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "      <th>skills_cleaned</th>\n",
       "      <th>desig_cleaned</th>\n",
       "      <th>job_desc_cleaned</th>\n",
       "      <th>loc_cleaned</th>\n",
       "      <th>job_type_cleaned</th>\n",
       "      <th>min_exp</th>\n",
       "      <th>max_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>6to10</td>\n",
       "      <td>team skills communication skills analytical sk...</td>\n",
       "      <td>senior exploit and vulnerability researcher</td>\n",
       "      <td>exp minimum years good understanding of ioc ru...</td>\n",
       "      <td>delhi ncr vikas puri</td>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>10to15</td>\n",
       "      <td>ppc logistics inventory management supply chai...</td>\n",
       "      <td>head scm</td>\n",
       "      <td>he should have handled a team of atleast direc...</td>\n",
       "      <td>sonepat</td>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR Analytics, Employee Engagement, Training, S...</td>\n",
       "      <td>Deputy Manager - Talent Management &amp; Leadershi...</td>\n",
       "      <td>Must be an effective communicator (written &amp; s...</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>5-9 yrs</td>\n",
       "      <td>15to25</td>\n",
       "      <td>hr analytics employee engagement training succ...</td>\n",
       "      <td>deputy manager talent management leadership de...</td>\n",
       "      <td>must be an effective communicator written spok...</td>\n",
       "      <td>delhi ncr</td>\n",
       "      <td>analytics</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQL, Javascript, Automation, Python, Ruby, Ana...</td>\n",
       "      <td>Associate Manager Data Engineering</td>\n",
       "      <td>7  -  10 years of overall experience in data e...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>7-10 yrs</td>\n",
       "      <td>10to15</td>\n",
       "      <td>sql javascript automation python ruby analytic...</td>\n",
       "      <td>associate manager data engineering</td>\n",
       "      <td>years of overall experience in data engineeri...</td>\n",
       "      <td>bengaluru</td>\n",
       "      <td>analytics</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounting, finance, cash flow, financial plan...</td>\n",
       "      <td>TS- GSA- Senior Analyst</td>\n",
       "      <td>Chartered Accountancy degree or MBA in Finance...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-3 yrs</td>\n",
       "      <td>3to6</td>\n",
       "      <td>accounting finance cash flow financial plannin...</td>\n",
       "      <td>ts gsa senior analyst</td>\n",
       "      <td>chartered accountancy degree or mba in finance...</td>\n",
       "      <td>gurgaon</td>\n",
       "      <td>missingjobtype</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          key_skills  \\\n",
       "0  team skills, communication skills, analytical ...   \n",
       "1  ppc, logistics, inventory management, supply c...   \n",
       "2  HR Analytics, Employee Engagement, Training, S...   \n",
       "3  SQL, Javascript, Automation, Python, Ruby, Ana...   \n",
       "4  accounting, finance, cash flow, financial plan...   \n",
       "\n",
       "                                           job_desig  \\\n",
       "0        Senior Exploit and Vulnerability Researcher   \n",
       "1                                           Head SCM   \n",
       "2  Deputy Manager - Talent Management & Leadershi...   \n",
       "3                 Associate Manager Data Engineering   \n",
       "4                            TS- GSA- Senior Analyst   \n",
       "\n",
       "                                     job_description               location  \\\n",
       "0  Exp: Minimum 5 years;Good understanding of IOC...  Delhi NCR(Vikas Puri)   \n",
       "1  He should have handled a team of atleast 5-6 d...                Sonepat   \n",
       "2  Must be an effective communicator (written & s...              Delhi NCR   \n",
       "3  7  -  10 years of overall experience in data e...              Bengaluru   \n",
       "4  Chartered Accountancy degree or MBA in Finance...                Gurgaon   \n",
       "\n",
       "    job_type experience  salary  \\\n",
       "0        NaN    5-7 yrs   6to10   \n",
       "1        NaN  10-17 yrs  10to15   \n",
       "2  Analytics    5-9 yrs  15to25   \n",
       "3  Analytics   7-10 yrs  10to15   \n",
       "4        NaN    1-3 yrs    3to6   \n",
       "\n",
       "                                      skills_cleaned  \\\n",
       "0  team skills communication skills analytical sk...   \n",
       "1  ppc logistics inventory management supply chai...   \n",
       "2  hr analytics employee engagement training succ...   \n",
       "3  sql javascript automation python ruby analytic...   \n",
       "4  accounting finance cash flow financial plannin...   \n",
       "\n",
       "                                       desig_cleaned  \\\n",
       "0        senior exploit and vulnerability researcher   \n",
       "1                                           head scm   \n",
       "2  deputy manager talent management leadership de...   \n",
       "3                 associate manager data engineering   \n",
       "4                              ts gsa senior analyst   \n",
       "\n",
       "                                    job_desc_cleaned            loc_cleaned  \\\n",
       "0  exp minimum years good understanding of ioc ru...  delhi ncr vikas puri    \n",
       "1  he should have handled a team of atleast direc...                sonepat   \n",
       "2  must be an effective communicator written spok...              delhi ncr   \n",
       "3   years of overall experience in data engineeri...              bengaluru   \n",
       "4  chartered accountancy degree or mba in finance...                gurgaon   \n",
       "\n",
       "  job_type_cleaned  min_exp  max_exp  \n",
       "0   missingjobtype        5        7  \n",
       "1   missingjobtype       10       17  \n",
       "2        analytics        5        9  \n",
       "3        analytics        7       10  \n",
       "4   missingjobtype        1        3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['merged'] = (df_train['desig_cleaned'] + ' ' + df_train['job_desc_cleaned'] + ' ' + df_train['skills_cleaned']\n",
    "                      + ' ' + df_train['job_type_cleaned'])\n",
    "\n",
    "df_test['merged'] = (df_test['desig_cleaned'] + ' ' + df_test['job_desc_cleaned'] + ' ' + df_test['skills_cleaned']\n",
    "                     + ' ' + df_test['job_type_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_train['salary'] = le.fit_transform(df_train['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    df_train[['merged', 'loc_cleaned', 'min_exp', 'max_exp']], \n",
    "    df_train['salary'], test_size=0.20, \n",
    "    stratify=df_train['salary'], random_state=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sample texts X_train:  15840\n",
      "No. of sample texts X_cv   :  3961\n"
     ]
    }
   ],
   "source": [
    "print('No. of sample texts X_train: ', len(X_train))\n",
    "print('No. of sample texts X_cv   : ', len(X_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the model & predict on CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged = X_train['merged']\n",
    "X_train_loc = X_train['loc_cleaned']\n",
    "\n",
    "X_cv_merged = X_cv['merged']\n",
    "X_cv_loc = X_cv['loc_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3), max_df=0.9)\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}')\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_loc = tf2.fit_transform(X_train_loc)\n",
    "\n",
    "X_cv_merged = tf1.transform(X_cv_merged)\n",
    "X_cv_loc = tf2.transform(X_cv_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(X_train['min_exp']).reshape(-1,1))\n",
    "X_cv_MinExp = sc1.transform(np.array(X_cv['min_exp']).reshape(-1,1))\n",
    "\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(X_train['max_exp']).reshape(-1,1))\n",
    "X_cv_MaxExp = sc2.transform(np.array(X_cv['max_exp']).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = hstack((X_train_merged, X_train_loc, X_train_MinExp, X_train_MaxExp))\n",
    "merged_cv  = hstack((X_cv_merged, X_cv_loc, X_cv_MinExp, X_cv_MaxExp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15840, 52318), (3961, 52318))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train.shape, merged_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(merged_train, label=y_train)\n",
    "test_data = lgb.Dataset(merged_cv, label=y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'multiclass',\n",
    "         'num_iterations': 80,\n",
    "         'learning_rate': 0.04,  \n",
    "         'num_leaves': 23,\n",
    "         'max_depth': 7, \n",
    "         'min_data_in_leaf': 28, \n",
    "         'max_bin': 10, \n",
    "         'min_data_in_bin': 3,   \n",
    "         'num_class': 6,\n",
    "         'metric': 'multi_logloss'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29632\n",
      "[LightGBM] [Info] Number of data points in the train set: 15840, number of used features: 3005\n",
      "[LightGBM] [Info] Start training from score -1.808567\n",
      "[LightGBM] [Info] Start training from score -1.481605\n",
      "[LightGBM] [Info] Start training from score -1.568616\n",
      "[LightGBM] [Info] Start training from score -2.531427\n",
      "[LightGBM] [Info] Start training from score -1.947616\n",
      "[LightGBM] [Info] Start training from score -1.724030\n",
      "[1]\tvalid_0's multi_logloss: 1.70572\n",
      "[2]\tvalid_0's multi_logloss: 1.67071\n",
      "[3]\tvalid_0's multi_logloss: 1.63995\n",
      "[4]\tvalid_0's multi_logloss: 1.61241\n",
      "[5]\tvalid_0's multi_logloss: 1.58778\n",
      "[6]\tvalid_0's multi_logloss: 1.56475\n",
      "[7]\tvalid_0's multi_logloss: 1.54412\n",
      "[8]\tvalid_0's multi_logloss: 1.52528\n",
      "[9]\tvalid_0's multi_logloss: 1.50764\n",
      "[10]\tvalid_0's multi_logloss: 1.4914\n",
      "[11]\tvalid_0's multi_logloss: 1.47662\n",
      "[12]\tvalid_0's multi_logloss: 1.46278\n",
      "[13]\tvalid_0's multi_logloss: 1.45016\n",
      "[14]\tvalid_0's multi_logloss: 1.43794\n",
      "[15]\tvalid_0's multi_logloss: 1.42652\n",
      "[16]\tvalid_0's multi_logloss: 1.41586\n",
      "[17]\tvalid_0's multi_logloss: 1.40573\n",
      "[18]\tvalid_0's multi_logloss: 1.39653\n",
      "[19]\tvalid_0's multi_logloss: 1.38762\n",
      "[20]\tvalid_0's multi_logloss: 1.37911\n",
      "[21]\tvalid_0's multi_logloss: 1.37108\n",
      "[22]\tvalid_0's multi_logloss: 1.36378\n",
      "[23]\tvalid_0's multi_logloss: 1.35683\n",
      "[24]\tvalid_0's multi_logloss: 1.3499\n",
      "[25]\tvalid_0's multi_logloss: 1.34391\n",
      "[26]\tvalid_0's multi_logloss: 1.33786\n",
      "[27]\tvalid_0's multi_logloss: 1.33237\n",
      "[28]\tvalid_0's multi_logloss: 1.32709\n",
      "[29]\tvalid_0's multi_logloss: 1.32216\n",
      "[30]\tvalid_0's multi_logloss: 1.31732\n",
      "[31]\tvalid_0's multi_logloss: 1.31305\n",
      "[32]\tvalid_0's multi_logloss: 1.30883\n",
      "[33]\tvalid_0's multi_logloss: 1.30475\n",
      "[34]\tvalid_0's multi_logloss: 1.30107\n",
      "[35]\tvalid_0's multi_logloss: 1.29756\n",
      "[36]\tvalid_0's multi_logloss: 1.29431\n",
      "[37]\tvalid_0's multi_logloss: 1.29084\n",
      "[38]\tvalid_0's multi_logloss: 1.28746\n",
      "[39]\tvalid_0's multi_logloss: 1.28438\n",
      "[40]\tvalid_0's multi_logloss: 1.28154\n",
      "[41]\tvalid_0's multi_logloss: 1.27893\n",
      "[42]\tvalid_0's multi_logloss: 1.27623\n",
      "[43]\tvalid_0's multi_logloss: 1.27356\n",
      "[44]\tvalid_0's multi_logloss: 1.27121\n",
      "[45]\tvalid_0's multi_logloss: 1.26865\n",
      "[46]\tvalid_0's multi_logloss: 1.26647\n",
      "[47]\tvalid_0's multi_logloss: 1.2645\n",
      "[48]\tvalid_0's multi_logloss: 1.26224\n",
      "[49]\tvalid_0's multi_logloss: 1.2604\n",
      "[50]\tvalid_0's multi_logloss: 1.25856\n",
      "[51]\tvalid_0's multi_logloss: 1.25676\n",
      "[52]\tvalid_0's multi_logloss: 1.25524\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's multi_logloss: 1.25361\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 1.25184\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 1.25028\n",
      "[56]\tvalid_0's multi_logloss: 1.24881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's multi_logloss: 1.24733\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 1.24587\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's multi_logloss: 1.24468\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 1.24333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 1.24213\n",
      "[62]\tvalid_0's multi_logloss: 1.24084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's multi_logloss: 1.23975\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's multi_logloss: 1.23853\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's multi_logloss: 1.23758\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 1.23639\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 1.23528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 1.23442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's multi_logloss: 1.23342\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 1.23243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 1.2317\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's multi_logloss: 1.23114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's multi_logloss: 1.23029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 1.22988\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 1.22913\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 1.22833\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's multi_logloss: 1.22776\n",
      "[78]\tvalid_0's multi_logloss: 1.22719\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's multi_logloss: 1.22663\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 1.22602\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.train(params=param,\n",
    "                 train_set=train_data,\n",
    "                 num_boost_round=100,\n",
    "                 valid_sets=[test_data])\n",
    "\n",
    "y_pred_class = lgbm.predict(merged_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.47942438778086344\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for x in y_pred_class:\n",
    "    predictions.append(np.argmax(x))\n",
    "\n",
    "print('accuracy:', accuracy_score(y_cv, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_merged = df_test['merged']\n",
    "X_test_loc = df_test['loc_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_merged = tf1.transform(X_test_merged)\n",
    "X_test_loc = tf2.transform(X_test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_MinExp = sc1.transform(np.array(df_test['min_exp']).reshape(-1,1))\n",
    "X_test_MaxExp = sc2.transform(np.array(df_test['max_exp']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test  = hstack((X_test_merged, X_test_loc, X_test_MinExp, X_test_MaxExp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgbm.predict(merged_test)\n",
    "\n",
    "y_pred_class = []\n",
    "for x in predictions:\n",
    "    y_pred_class.append(np.argmax(x))\n",
    "\n",
    "y_pred_class = le.inverse_transform(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(data=y_pred_class, columns=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "df_sub.to_excel(writer, index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
